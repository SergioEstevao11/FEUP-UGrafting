Serj
serj_07
Online

Serj â€” 01/16/2024 7:43 PM
Holafly data
Serj â€” 01/17/2024 3:40 PM
Attachment file type: archive
lab6_code.zip
8.75 KB
Attachment file type: acrobat
6lab-eng.pdf
100.27 KB
Serj â€” 01/17/2024 8:54 PM
rosrun tf static_transform_publisher 0 0 0 0 0 0 map odom 100 
rosrun amcl amcl _use_sim_time:=true \
_use_map_topic:=true scan:=/base_scan \
_odom_frame_id:=/odom _base_frame_id:=/base_link \
_global_frame_id:=/map _tf_broadcast:=false
Serj â€” 01/21/2024 1:58 PM
[
...
  {
    "_id": {
      "staff": "Ashley Rivera"
    },
    "value": {
      "totAmount": "19.950",
      "totCnt": 6,
      "avgAmount": "3.325"
    }
  }
  ...
]
Using the dvdrent collection for each stuff member and rentals he charged in years 2014 and 2015 (payment_date) for films in category "Comedy" calculate:

total paid amount
total number of charged rentals
average amount of rent. Round the average to 3 decimal places.
All numbers should be formated to three places.

Attribute names and the overall result format can be seen from the example above.
Image
Serj â€” 02/03/2024 12:17 PM
Chapter 1: Introduction (1 or 2 paragraphs per subsection)
1.1 Problem statement - motivaÃ§Ã£o mais teÃ³rica
1.2 Motivation (why is this problem relevant?)
1.3 Aim and Goals 
-- Aims (no final do projeto, o que quero ter? algoritmo? metodologia?)
-- Goals (aim mais especifico) - para chegar Ã  aim, o que tenho que resolver antes
1.4 Expected contributions
-- Scientific contributions
-- Practical contributions 
-- Technological contributions 
1.5 Document structure/organisation

Chapter 2: Literature Review

Chapter 3: Methods and Materials
3.1 Problem formalisation - formulaÃ§Ã£o mais matemÃ¡tica
3.2 Research Hypotheses (H1, H2, ...)
3.3 Methodological approach to demonstrate the hypotheses
-- What and how?
-- methods, techniques, tools, etc
-- materials: datasets
-- functional/process pipelines

3.4 Work plan 
-- Task descriptions
-- Gantt chart (calendar)

Chapter 4: Conclusions
-- Final remarks (literature review, methodology, etc.)
-- SWOT Analysis (over the project)
-- SMART Analysis (over the goals)
  - Specific
  - Measurable
  - Attainable
  - Realistic
  - Timely
Serj â€” 02/27/2024 2:31 PM
Attachment file type: acrobat
account-statement_2024-02-01_2024-02-27_pt-pt_f1c177.pdf
51.19 KB
Serj â€” 02/29/2024 3:04 AM
Hello Dawid! Thank you for the reminder, with the thesis and the homecoming I completly forgot, sorry :/

Well about recommendation, here they go:

Bars: Adega Leonor, the bread and butter of Porto, small bar where you are supposed to order your drink and then go outside and drink (yes we don't have dry law here after 22h eheheh), alot of people outside, mostly students, amazing vibes overall; Eleven Sports Bar Downtown, more of a sitdown place, also one of my favs; 77, a in between of the previous two
Expand
message.txt
3 KB
Serj â€” 03/09/2024 4:13 PM
O que fiz:

consultei implementaÃ§Ãµes algortimos state of the art de supervised learning, Vision transformers pareceram-me a mais indicada visto que a maioria tem isto por base
consegui por um Swin transformer a correr
consegui uma source de datasets
Estava a ver implementaÃ§Ãµes de diferentes


accuracy com o mapa de incerteza

loss landscape
Serj â€” 03/14/2024 3:26 PM
Self-Supervision + Uncertainty Quantification


Goal: Melhorar Self-Supervision com Uncertainty Quantification

Formas     - dando informaÃ§Ã£o extra que UQ fornece
    
melhorando o modelo usando UQ

Passos:

Encontrar um modelo self-supervision: check
Quantificar incerteza desse modelo:
Usar essa incerteza para algo
Serj â€” 03/14/2024 4:03 PM
2 cenÃ¡rio - Stochastic-attention ou Sub-Network

Transpor para vÃ¡rias tasks

brincar com a loss function
Serj â€” 03/25/2024 12:13 PM
Soares, sexo "em aberto", gÃ©nero radical, 22 anos, oriunda de terras onde a palavra "BUENOS" antecede sempre a palavra "DIAS". Deu entrada no SU, por estar enFARTAda de procurar um desporto em que nÃ£o seja boa.

Corpo do Texto:
A Soares Ã© a prÃ³pria definiÃ§Ã£o de "quem nÃ£o arrisca, nÃ£o petisca", com um currÃ­culo de desportos radicais que faria o mais destemido dos aventureiros corar. A sua paixÃ£o pela patinagem artÃ­stica Ã© tÃ£o intensa que sonha em transformar a pista de gelo numa pista de fogo, sÃ³ para elevar o nÃ­vel do desafio. Quando corre, parece que estÃ¡ sempre a fugir de um predador invisÃ­vel, tal Ã© a velocidade. No skate, realiza manobras com um nÃ­vel de complexidade que faria os fÃ­sicos questionarem as leis da gravidade. E quanto ao surf, Ã© sabido que atÃ© os tubarÃµes se afastam para admirar as suas habilidades. NÃ£o esquecendo a sua inclinaÃ§Ã£o para histÃ³rias romÃ¢nticas com um toque vintage, especialmente aquelas que envolvem beijos com sabor a nostalgia â€” porque, afinal, a experiÃªncia vem com a idade.

Selecione as etiologias possÃ­veis para o enFARTO:
A) Taquicardia funkeira â€“ quando o coraÃ§Ã£o bate ritmado com o funk mais prÃ³ximo.
B) Ãšlcera alcoÃ³lica â€“ condiÃ§Ã£o marcada pela confianÃ§a desmedida no shot da casa do tasco.
C) O Sistema.
Serj â€” 03/26/2024 1:09 PM
Soares, sexo "em aberto", gÃ©nero radical, 22 anos, oriunda de terras onde a palavra "BUENOS" antecede sempre a palavra "DIAS". Deu entrada no SU, por estar enFARTAda de procurar um desporto em que nÃ£o seja boa.

Corpo do Texto:
A Soares Ã© a prÃ³pria definiÃ§Ã£o de "quem nÃ£o arrisca, nÃ£o petisca", e acreditem, ela acabou por petiscar bastante. Desde os dias de patinagem artÃ­stica, a Soares sempre mostrou aptidÃ£o para cair, levantar-se outra vez, cair e levantar-se de novo, num ciclo que se alimenta a si mesmo mas que acaba por ter um fim quando damos por ela saciando o que procurÃ¡vamos. Ã‰ desta energia de manter este ciclo que a Soares fez um dos seus grandes feitos que Ã© entrar em Medicina. Trocou os pisos de madeira, sapatos com rodas, fatiotas engraÃ§adas, bebidas energÃ©ticas e campeonatos internacionais por chÃ£o de borracha, crocs e sapatinhos brancos, bata branca, cafÃ© e cerveja, e festas acadÃ©micas. Daqui, longe de casa e longe de amigos, arriscou e encontrou outra casa e mais amigos. Riu, chorou, desesperou, bebeu, bebeu, bebeu, desesperou mais um bocadinho, correu queimas e latadas, estudou um bocadinho lÃ¡ pelo meio, danÃ§ou todas as mÃºsicas de funk que ouvia religiosamente, ganhou depressÃ£o crÃ³nica depois de ter visto o quÃ£o lindo Ã© NÃ¡poles, ganhou ansiedade crÃ³nica em todas as passadeiras visto que em NÃ¡poles quase era atropelada por uma Vespa cinco vezes ao dia, e por fim, bebeu. 
NÃ£o esquecendo, por fim, a sua inclinaÃ§Ã£o para histÃ³rias romÃ¢nticas com um toque vintage â€” porque, afinal, a experiÃªncia vem com a idade. 
Senhoras e Senhoras, a Soares, desportista, futura mÃ©dica, professional risk taker, arriscadora de gema e dona do sorriso mais contagiante da academia.

Selecione as etiologias possÃ­veis para o enFARTO:
A) Taquicardia funkeira â€“ quando o coraÃ§Ã£o bate ritmado com o funk mais prÃ³ximo.
B) Ãšlcera alcoÃ³lica â€“ condiÃ§Ã£o marcada pela confianÃ§a desmedida no shot da casa.
C) O Sistema.
Serj â€” 03/28/2024 11:03 PM
https://www.instagram.com/reel/C4qN1uFukwL/?utm_source=ig_web_button_share_sheet&igsh=MzRlODBiNWFlZA==

exquisite.travel.adventures
I mean you already know Iâ€™m inâ€¦ ðŸ˜ŽðŸ¤

Click the link in bio to build that dream trip youâ€™ve been waiting for.. ðŸ”—ðŸ‘‰

Theresa Schmidt | Travel Advisor
Exquisite Travel and Adventures
theresa@exquisitetravelandadventures.com

#exquisitetravelsandadventures #travelwiththeresa

#virtuosotravelagent #virtuosotraveladvisor #travelreels #travelinspo #inst...
Likes
521285

Instagram
Serj â€” 04/05/2024 3:59 AM
Done:

Direct Modelling
plotting:  3d scatter plot / 3d histograms
Investigation of usage of other dataset: not finished
involves some significant changes to the architecture, post poned since focus should be to finish what is now being done-

Next week plans:

documentation for the uncertainty progression over training
start training more robust model
analysis of the usage for other tasks

ReuniÃ£o:
o que fiz
paper: datas, seria uma possibilidade, compensaria?


notas:
professor nÃ£o vai poder
falta orÃ§amento, nÃ£o depende do professor
Serj â€” 04/05/2024 5:52 AM
To my favorite cowboy

To my FIP FIP Partner

Wanted




5 tvaroh cakes

To be read only by my favorito cowboy, Barbora:

Distance is quite a challenge, eventhough we both actually are quite well off, it is a certain thing we do have our ups and sometimes our downs, it's natural, our minds do funny trick and backflips with thoughts. But you know, it feels worth it. I do feel that a having a significant person on the other side 

With you I feel more alive than ever, I let myself feel feelings. There is nothing more that I want in this world then see you happy, us happy


P.S. If you are not Barbora and ended up reading this... let's say this
Serj â€” 04/14/2024 2:30 AM
Bachelors in Software and Computing Engineering.
Finishing my Masters in Software and Computing Engineering, writing a thesis about Deep Learning, namely uncertainty quantification and self-supervised learning.

Member of the Software Engineering student branch, where I participated and was a Project Leader of a full-stack project.

Participated in multiple hackathons.

Went on abroad study programs in Poland and Romania.
I'm SÃ©rgio EstÃªvÃ£o, a Masters student in Informatics and Computer Engineering at the University of Porto. I am eager to apply for the Junior Software Developer position at Critical Software, attracted by your commitment to engineering excellence and community values, which resonate deeply with my own professional aspirations and personal ethics.

As an active member of Portoâ€™s Software Engineering Studentâ€™s Association, I've led 
a s
full-stack project named "TimeTableSelector," sharpening my project management and team collaboration skills. This role, along with my position as an embedded software engineer at Smartex.ai, where I developed hardware simulations to refine software testing processes, has prepared me well for the high standards and innovative projects.

My experience at CEiiA developing software for satellite systems has ingrained a strong capability to deliver high-quality software under rigorous conditions, a requisite for the challenging environments at Critical.

Furthermore, my current research on deep learning, namely uncertainty quantification and self-supervised learning, and my extensive involvement in diverse software projects during my academic career underscore my proactive approach to learning and my readiness to contribute to diverse development ecosystems.

I am particularly drawn to Critical Software because of its mission to make the world a better, safer place through technology. During my academic years, I have accompanied Critical Software's work, and now I am excited about the opportunity to contribute to meaningful projects that align with my desire to create impactful technological solutions.

Thank you for considering my application. I look forward to discussing how I can contribute to your teams and grow within your esteemed company.

Best regards,

SÃ©rgio EstÃªvÃ£o
Serj â€” 04/16/2024 6:24 PM
data augmentation - dirty side of self-supervision, very arbitrary

todo:

dar fix Ã  loss function: para direct modelling e para mc-dropout

analizar qual seria a melhor opÃ§Ã£o

comparar com algoritmo normais (sem nada)

ver se existe melhor desempenho (melhor accuracy, serÃ¡ que falsos positivos desaparecem)

adicionar image net aos datasets

adicionar cityscape para tentar fazer segmentation
Serj â€” 04/19/2024 11:46 AM
pontos variancia mÃ©dia
calcular entropia

ver imagens


use tiny imagenet C
esta semana:

treino treino treino
hyper parameter tuning
tuning na loss function
implementaÃ§Ã£o da image-net com augmentaÃ§Ãµes do DINOV2

descobertas:

vit sÃ£o muito volateis no treino e exigem lr muito baixas (referencia do DINO e outros papers)
image augmentation: lado obscuro de self-supervison. pequenas alteraÃ§Ãµes da augmentaÃ§Ã£o podem fazer com que de facto o modelo aprenda ou nÃ£o
accuracy do vit em geral: pÃ©ssima
resultado do mcdropout: dubio



std_loss1: garante um valor de incerteza minimo acima de lambda2

std_loss2: tenta diminuir a variancia
Serj â€” 05/16/2024 5:01 PM
Attachment file type: acrobat
resume.pdf
114.99 KB
Attachment file type: acrobat
licenciatura_certificado_2.pdf
675.33 KB
Serj â€” 05/17/2024 1:04 PM
Attachment file type: acrobat
Pedido_contrato_de_bolsa_Sergio_Miguel_Rosa_Estevao.docx.pdf
112.98 KB
Serj â€” 05/21/2024 7:39 PM
My name is SÃ©rgio, and I'm finishing my Master's in Software Engineering at the University of Porto and writing my thesis about Uncertainty Quantification in Self-Supervised Learning.
Besides the information about me provided, I was part of the Software Engineer Students' Union, where I coordinated a full-stack project for 1y, and I also have a Deep Learning Specialization by DeepLearning.AI.
Continental has always been a household name. Throughout my years studying, I have interacted with the company at job fairs, watched their work, and even had friends who interned and highly recommended it. Now that I'm looking to start my working life and saw this job offer in one of my areas of interest, I couldn't let it pass. I hope to be part of the team in the future!
Replicabilidade


Testar com outros metodos
outras loss functions
outras maneiras de quantificar incerteza



ir escrevendo pouco a pouco, nao escrever + em partes secundarias
Serj â€” 05/24/2024 12:20 AM
barlow twin self-supervision - https://github.com/wgcban/mix-bt


uncertainty threshold
hyperparameter tunning
treinar com vit + imagenet
out of distribution testing
different loss function (OG focasse em manter um nivel de incerteza minimo, para garantir que os ensembles nÃ£o colapsam)
GitHub
GitHub - wgcban/mix-bt: Official PyTorch Implementation of Guarding...
Official PyTorch Implementation of Guarding Barlow Twins Against Overfitting with Mixed Samples - wgcban/mix-bt
GitHub - wgcban/mix-bt: Official PyTorch Implementation of Guarding...
Serj â€” 05/25/2024 10:59 PM
PT50 0018 0003 1855 6811 0201 8
Serj â€” 05/26/2024 12:41 AM
PART 1: impacto de medir a inceteza no final de redes com 




PART 2: thresholding com incerteza

testar com:

thresholding em:
models que aprenderam com incerteza
models que aprenderam sem incerteza

sem thresholding

que thresholding pode ser feito?? baseado na distribuiÃ§Ã£o de incertezas medidas (se a incerteza que for medida numa prediction estiver nos top 10% (valor arbitrÃ¡rio), rejeitar)
Serj â€” 05/26/2024 2:18 AM
TODO:
mudar o embedding size de 128 para 1024

clarificar como o treino linear Ã© feito (retirando a MLP layers)

mudar o linear training para incluir o MLP, pq este menino precisa de stochacity
Serj â€” 05/28/2024 1:25 PM
Responsible AI
Serj â€” 05/28/2024 1:46 PM
TODO:

Modelos com e sem uncertainty loss

linear probing para dataset diferentes

linear probing em cima e fora da UQ-MLP
Serj â€” 05/28/2024 6:42 PM
-> ver accuracy dos indices que nÃ£o foram selecionados

Notas:

informaÃ§Ã£o para o end-user, podemos dar as samples que nÃ£o foram selecionadas, mas como uma flag!

informaÃ§Ã£o para os devs, no aspeto de dizer quais as lacunas da rede, que tipo de classes a rede tem mais incerteza.
Serj â€” 05/31/2024 8:08 PM
https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar
Serj â€” 06/01/2024 11:14 PM
https://github.com/SergioEstevao11/FEUP-UGrafting.git
https://github.com/SergioEstevao11/FEUP-UGrafting.git
https://github.com/SergioEstevao11/FEUP-UGrafting.git
https://github.com/SergioEstevao11/FEUP-UGrafting.git
https://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@github.com/SergioEstevao11/FEUP-UGrafting.git
Serj â€” 06/01/2024 11:24 PM
python main_pretrain.py --cosine --nh 20 --dataset cifar10 --lamda1 1 --lamda2 0.5 --epoch 100 --batch_size 64 --model resnet18
Serj â€” Yesterday at 12:17 AM
wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz
Serj â€” Today at 2:24 AM
Train: [4][1250/1252]    BT 1.185 (1.182)    DT 0.009 (0.017)    loss 2.236 (2.271)
ensemble 0, epoch 4, total time 1479.70
total loss: 2.270588243118768, std_loss: 0.08276451711045886, std_loss2: 6.697598635856842
Traceback (most recent call last):
  File "/home/sergio/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.8/multiprocessing/queues.py", line 107, in get
    if not self._poll(timeout):
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/usr/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/usr/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/sergio/.local/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    errorif_any_worker_fails()
RuntimeError: DataLoader worker (pid 255580) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "main_pretrain.py", line 217, in <module>
    main()
  File "main_pretrain.py", line 163, in main
    features, std, labels = evaluate_uncertainty(test_loader, model)
  File "/home/sergio/Documents/FEUP-UGrafting/UncertaintyAware-SSL/Train/pretrain.py", line 87, in evaluate_uncertainty
    for idx, ((image1, image2), labels) in enumerate(val_loader):
  File "/home/sergio/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next
    data = self._next_data()
  File "/home/sergio/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1329, in
line 1295, in _get_data
    success, data = self._try_get_data()
  File "/home/sergio/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1146, in _try_get_data
    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
RuntimeError: DataLoader worker (pid(s) 255580) exited unexpectedly
Train: [4][1250/1252]BT 1.185 (1.182)DT 0.009 (0.017)loss 2.236 (2.271)
ensemble 0, epoch 4, total time 1479.70
total loss: 2.270588243118768, std_loss: 0.08276451711045886, std_loss2: 6.697598635856842
Traceback (most recent call last):
  File "/home/sergio/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1133, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
Expand
message.txt
3 KB
Serj â€” Today at 2:40 AM
class DataAugmentationDINO(object):
    def init(self, globalcrops_scale, local_crops_scale, local_crops_number, image_size=64):
        flip_and_color_jitter = transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomApply(
                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],
                p=0.8
            ),
            transforms.RandomGrayscale(p=0.2),
        ])

        normalize = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
        ])
        # first global crop
        self.global_transfo1 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            transforms.GaussianBlur(3, 1.0),
            normalize,
        ])
        # second global crop
        self.global_transfo2 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            transforms.GaussianBlur(3, sigma=0.1),
            transforms.Solarization(0.2),
            normalize,
        ])
        # transformation for the local small crops
        self.local_crops_number = local_crops_number
        self.local_transfo = transforms.Compose([
            transforms.RandomResizedCrop(int(96/(244/image_size)), scale=local_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            transforms.GaussianBlur(3, 0.5),
            normalize,
        ])

    def call(self, image):
        crops = []
        crops.append(self.global_transfo1(image))
        crops.append(self.global_transfo2(image))
        # for  in range(self.local_crops_number):
        #     crops.append(self.local_transfo(image))
        return crops[0], crops[1]
class Solarization(object):
    """
    Apply Solarization to the PIL image.
    """
    def init(self, p):
        self.p = p

    def call(self, img):
        if random.random() < self.p:
            return ImageOps.solarize(img)
        else:
            return img
class GaussianBlur(object):
    """
    Apply Gaussian Blur to the PIL image.
    """
    def init(self, p=0.5, radius_min=0.1, radius_max=2.):
        self.prob = p
        self.radius_min = radius_min
        self.radius_max = radius_max

    def call(self, img):
        do_it = random.random() <= self.prob
        if not do_it:
            return img

        return img.filter(
            ImageFilter.GaussianBlur(
                radius=random.uniform(self.radius_min, self.radius_max)
            )
        )
Serj â€” Today at 2:47 AM
class DataAugmentationDINO(object):
    def init(self, global_crops_scale, local_crops_scale, local_crops_number, image_size=64):
        flip_and_color_jitter = transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomApply(
                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],
                p=0.8
            ),
            transforms.RandomGrayscale(p=0.2),
        ])

        normalize = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
        ])
        # first global crop
        self.global_transfo1 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            utils.GaussianBlur(1.0),
            normalize,
        ])
        # second global crop
        self.global_transfo2 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            utils.GaussianBlur(0.1),
            utils.Solarization(0.2),
            normalize,
        ])
        # transformation for the local small crops
        self.local_crops_number = local_crops_number
        self.local_transfo = transforms.Compose([
            transforms.RandomResizedCrop(int(96/(244/image_size)), scale=local_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            utils.GaussianBlur(p=0.5),
            normalize,
        ])
Serj â€” Today at 5:19 PM
Image
Serj â€” Today at 7:47 PM
from torch.utils.data import DataLoader, random_split
import torchvision.transforms as transforms
from torchvision import datasets
import torch
from utils.util import TwoCropTransform, GaussianBlur, Solarization
from PIL import Image

# search tiny imagenet C 
# from https://github.com/clint-kristopher-morris/DINO_concise/blob/main/notebooks_/Concise_DINO-Demo.ipynb

class DataAugmentationDINO(object):
    def __init__(self, global_crops_scale, local_crops_scale, local_crops_number, image_size=64):
        flip_and_color_jitter = transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomApply(
                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],
                p=0.8
            ),
            transforms.RandomGrayscale(p=0.2),
        ])

        normalize = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
        ])
        # first global crop
        self.global_transfo1 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(1.0),
            normalize,
        ])
        # second global crop
        self.global_transfo2 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(0.1),
            Solarization(0.2),
            normalize,
        ])
        # transformation for the local small crops
        self.local_crops_number = local_crops_number
        self.local_transfo = transforms.Compose([
            transforms.RandomResizedCrop(int(96/(244/image_size)), scale=local_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(p=0.5),
            normalize,
        ])

    def __call__(self, image):
        crops = []
        crops.append(self.global_transfo1(image))
        crops.append(self.global_transfo2(image))
        # for _ in range(self.local_crops_number):
        #     crops.append(self.local_transfo(image))
        return crops[0], crops[1]
    

def data_loader(dataset="cifar10", batch_size=512, semi=False, semi_percent=10, num_cores=12):
    if dataset == 'cifar10':
        mean = (0.4914, 0.4822, 0.4465)
        std = (0.2023, 0.1994, 0.2010)
    elif dataset == 'cifar100':
        mean = (0.5071, 0.4867, 0.4408)
        std = (0.2675, 0.2565, 0.2761)
    elif dataset == "svhn":
        mean = (0.4376821, 0.4437697, 0.47280442)
        std = (0.19803012, 0.20101562, 0.19703614)

    normalize = transforms.Normalize(mean=mean, std=std)
    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        normalize,
    ])
    val_transform = transforms.Compose([
        transforms.ToTensor(),
        normalize,
    ])
    sampler = None
    # datasets
    if dataset == "cifar10":
        train_dataset = datasets.CIFAR10(root='../../DATA2/', train=True, download=True, transform=train_transform)
        test_dataset = datasets.CIFAR10(root='../../DATA2/', train=False, download=True, transform=val_transform)

    elif dataset == "cifar100":
        train_dataset = datasets.CIFAR100(root='../../DATA2/', train=True, download=True, transform=train_transform)
        test_dataset = datasets.CIFAR100(root='../../DATA2/', train=False, download=True, transform=val_transform)
    elif dataset == "svhn":
        train_dataset = datasets.SVHN(
            root='../../DATA2/', split="train", download=True, transform=train_transform
        )
        test_dataset = datasets.SVHN(
            root='../../DATA2/', split="test", download=True, transform=val_transform
        )
    elif dataset == "tinyimagenet":
        pass
        # train_dataset = datasets.ImageFolder(root='../../DATA2/tiny-imagenet-200/train', transform=DataAugmentationDINO)
        # test_dataset = datasets.ImageFolder(root='../../DATA2/tiny-imagenet-200/val', transform=val_transform)
... (180 lines left)
Collapse
message.txt
12 KB
from __future__ import print_function

import math
import torch
import torch.optim as optim
import numpy as np
Expand
message.txt
6 KB
nt
from torch.utils.data import DataLoader, random_split
import torchvision.transforms as transforms
from torchvision import datasets
import torch
from utils.util import TwoCropTransform, GaussianBlur, Solarization
from PIL import Image

# search tiny imagenet C 
# from https://github.com/clint-kristopher-morris/DINO_concise/blob/main/notebooks_/Concise_DINO-Demo.ipynb

class DataAugmentationDINO(object):
    def __init__(self, global_crops_scale, local_crops_scale, local_crops_number, image_size=64):
        flip_and_color_jitter = transforms.Compose([
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomApply(
                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],
                p=0.8
            ),
            transforms.RandomGrayscale(p=0.2),
        ])

        normalize = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
        ])
        # first global crop
        self.global_transfo1 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(1.0),
            normalize,
        ])
        # second global crop
        self.global_transfo2 = transforms.Compose([
            transforms.RandomResizedCrop(image_size, scale=global_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(0.1),
            Solarization(0.2),
            normalize,
        ])
        # transformation for the local small crops
        self.local_crops_number = local_crops_number
        self.local_transfo = transforms.Compose([
            transforms.RandomResizedCrop(int(96/(244/image_size)), scale=local_crops_scale, interpolation=Image.BICUBIC),
            flip_and_color_jitter,
            GaussianBlur(p=0.5),
            normalize,
        ])

    def __call__(self, image):
        crops = []
        crops.append(self.global_transfo1(image))
        crops.append(self.global_transfo2(image))
        # for _ in range(self.local_crops_number):
        #     crops.append(self.local_transfo(image))
        return crops[0], crops[1]
    

def data_loader(dataset="cifar10", batch_size=512, semi=False, semi_percent=10, num_cores=12):
    if dataset == 'cifar10':
        mean = (0.4914, 0.4822, 0.4465)
        std = (0.2023, 0.1994, 0.2010)
    elif dataset == 'cifar100':
        mean = (0.5071, 0.4867, 0.4408)
        std = (0.2675, 0.2565, 0.2761)
    elif dataset == "svhn":
        mean = (0.4376821, 0.4437697, 0.47280442)
        std = (0.19803012, 0.20101562, 0.19703614)

    normalize = transforms.Normalize(mean=mean, std=std)
    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        normalize,
    ])
    val_transform = transforms.Compose([
        transforms.ToTensor(),
        normalize,
    ])
    sampler = None
    # datasets
    if dataset == "cifar10":
        train_dataset = datasets.CIFAR10(root='../../DATA2/', train=True, download=True, transform=train_transform)
        test_dataset = datasets.CIFAR10(root='../../DATA2/', train=False, download=True, transform=val_transform)

    elif dataset == "cifar100":
        train_dataset = datasets.CIFAR100(root='../../DATA2/', train=True, download=True, transform=train_transform)
        test_dataset = datasets.CIFAR100(root='../../DATA2/', train=False, download=True, transform=val_transform)
    elif dataset == "svhn":
        train_dataset = datasets.SVHN(
            root='../../DATA2/', split="train", download=True, transform=train_transform
        )
        test_dataset = datasets.SVHN(
            root='../../DATA2/', split="test", download=True, transform=val_transform
        )
    elif dataset == "tinyimagenet":
        pass
        # train_dataset = datasets.ImageFolder(root='../../DATA2/tiny-imagenet-200/train', transform=DataAugmentationDINO)
        # test_dataset = datasets.ImageFolder(root='../../DATA2/tiny-imagenet-200/val', transform=val_transform)
    if semi:
        per = semi_percent / 100
        x = int(per * len(train_dataset))
        y = int(len(train_dataset) - x)
        train, _ = random_split(train_dataset, [x, y])
    else:
        train = train_dataset

    train, val = random_split(train, [int(0.8 * len(train)),
                                      len(train) - int(0.8 * len(train))], generator=torch.Generator().manual_seed(42))

    train_loader = DataLoader(train,
                              batch_size=batch_size,
                              shuffle=True,
                              num_workers=num_cores,
                              drop_last=False
                              )
    val_loader = DataLoader(val,
                            batch_size=batch_size,
                            shuffle=False,
                            num_workers=num_cores,
                            drop_last=False)

    test_loader = DataLoader(test_dataset,
                             batch_size=batch_size,
                             num_workers=num_cores,
                             drop_last=False)

    targets = torch.cat([y for x, y in test_loader], dim=0).numpy()
    return train_loader, val_loader, test_loader, targets


def set_loader_simclr(dataset, batch_size, num_workers, data_dir='../../DATA2/', size_randomcrop=32):
    # construct data loader
    if dataset == 'cifar10':
        mean = (0.4914, 0.4822, 0.4465)
        std = (0.2023, 0.1994, 0.2010)
    elif dataset == 'cifar100':
        mean = (0.5071, 0.4867, 0.4408)
        std = (0.2675, 0.2565, 0.2761)
    elif dataset == "svhn":
        mean = (0.4376821, 0.4437697, 0.47280442)
        std = (0.19803012, 0.20101562, 0.19703614)
    else:
        raise ValueError('dataset not supported: {}'.format(dataset))
    normalize = transforms.Normalize(mean=mean, std=std)

    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(size=size_randomcrop, scale=(0.2, 1.)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomApply([
            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)
        ], p=0.8),
        transforms.RandomGrayscale(p=0.2),
        transforms.ToTensor(),
        normalize,
    ])

    if dataset == 'cifar10':
        train_dataset = datasets.CIFAR10(root=data_dir,
                                         transform=TwoCropTransform(train_transform),
                                         download=True)
    elif dataset == 'cifar100':
        train_dataset = datasets.CIFAR100(root=data_dir,
                                          transform=TwoCropTransform(train_transform),
                                          download=True)
    elif dataset == 'svhn':
        train_dataset = datasets.SVHN(
            root=data_dir, split="train", download=True, transform=TwoCropTransform(train_transform)
        )

    else:
        raise ValueError(dataset)

    print(f"train dataset length is {len(train_dataset)}")
    train_sampler = None
    image_shape = (3, size_randomcrop, size_randomcrop)
    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),
        num_workers=num_workers, pin_memory=False, sampler=train_sampler)

    return train_loader, image_shape

def dataloader_UQ(dataset, batch_size, num_workers, data_dir='../../DATA2/', size_randomcrop=32): #still work this out
    # construct data loader
    if dataset == 'cifar10':
        mean = (0.4914, 0.4822, 0.4465)
        std = (0.2023, 0.1994, 0.2010)
    elif dataset == 'cifar100':
        mean = (0.5071, 0.4867, 0.4408)
        std = (0.2675, 0.2565, 0.2761)
    elif dataset == "svhn":
        mean = (0.4376821, 0.4437697, 0.47280442)
        std = (0.19803012, 0.20101562, 0.19703614)
    elif dataset == "imagenet":
        mean = (0.4802, 0.4481, 0.3975) #dummy
        std = (0.2770, 0.2691, 0.2821) #dummy
    else:
        raise ValueError('dataset not supported: {}'.format(dataset))
    normalize = transforms.Normalize(mean=mean, std=std)

    #data transformations
    crop_size = size_randomcrop

    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(size=crop_size, scale=(0.2, 1.)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomApply([
            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)
        ], p=0.8),
        transforms.RandomGrayscale(p=0.2),
        transforms.ToTensor(),
        normalize,
    ])

    val_transform = transforms.Compose([
        transforms.ToTensor(),
        normalize,
    ])

    if dataset == "cifar10":
        train_dataset = datasets.CIFAR10(root=data_dir,
                                          transform=TwoCropTransform(train_transform),
                                          download=True)
        test_dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=TwoCropTransform(val_transform))

    elif dataset == "cifar100":
        train_dataset = datasets.CIFAR100(root=data_dir,
                                          transform=TwoCropTransform(train_transform),
                                          download=True)
        test_dataset = datasets.CIFAR100(root=data_dir, train=False, download=True, transform=TwoCropTransform(val_transform))
    elif dataset == "svhn":
        train_dataset = datasets.SVHN(
            root=data_dir, split="train", download=True, transform=TwoCropTransform(train_transform)
        )
        test_dataset = datasets.SVHN(
            root=data_dir, split="test", download=True, transform=TwoCropTransform(val_transform)
        )

    elif dataset == "imagenet":
        crop_size = 64
        data_transform = DataAugmentationDINO(
            image_size = crop_size,
            global_crops_scale=(0.4, 1.0), 
            local_crops_scale=(0.05, 0.4), 
            local_crops_number=6
        )

        val_transform = val_transform = transforms.Compose([
            transforms.RandomResizedCrop(crop_size, scale=(0.4, 1.0), interpolation=Image.BICUBIC),
            transforms.ToTensor(),
            normalize,
        ])


        # train_dataset = datasets.ImageFolder(root='../../DATA2/tiny-imagenet-200/train', transform=data_transform)
        # test_dataset = datasets.ImageFolder(root='../../DATA2/tiny-imagenet-200/val', transform=val_transform)
        train_dataset = datasets.ImageNet(root='../../datasets/imagenet/', split="train", transform=data_transform)
        test_dataset = datasets.ImageNet(root='../../datasets/imagenet/', split="val", transform=TwoCropTransform(val_transform))

    else:
        raise ValueError(dataset)

    print(f"train dataset length is {len(train_dataset)}")
    train_sampler = None
    image_shape = (3, crop_size, crop_size)


   
    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),
        num_workers=num_workers, pin_memory=False, sampler=train_sampler)
    
    test_loader = DataLoader(test_dataset,
                             batch_size=batch_size,
                             num_workers=num_workers,
                             drop_last=False)

    return train_loader, image_shape, test_loader
