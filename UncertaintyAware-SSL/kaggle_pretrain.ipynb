{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"625baafd-60d3-4d1f-9e8f-8d8d893a630f","_uuid":"39a902da-42ef-4dc3-9499-aaece54a6071","trusted":true},"source":["# PRETRAINING"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"13f901ad-a73f-42ef-8eca-c17f479d28b7","_uuid":"920acd5a-d110-4ef4-824f-f59d25013ef6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ood_metrics in /home/sergio/.env/FEUP/lib/python3.10/site-packages (1.1.2)\n","Requirement already satisfied: numpy<2.0,>=1.22 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from ood_metrics) (1.26.4)\n","Requirement already satisfied: scikit-learn<2.0,>=1.0 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from ood_metrics) (1.4.1.post1)\n","Requirement already satisfied: matplotlib<4.0,>=3.0 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from ood_metrics) (3.8.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (1.4.5)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (4.49.0)\n","Requirement already satisfied: cycler>=0.10 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (0.12.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (3.1.1)\n","Requirement already satisfied: pillow>=8 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (10.2.0)\n","Requirement already satisfied: packaging>=20.0 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from matplotlib<4.0,>=3.0->ood_metrics) (23.2)\n","Requirement already satisfied: scipy>=1.6.0 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.0->ood_metrics) (1.12.0)\n","Requirement already satisfied: joblib>=1.2.0 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.0->ood_metrics) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.0->ood_metrics) (3.3.0)\n","Requirement already satisfied: six>=1.5 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0,>=3.0->ood_metrics) (1.16.0)\n"]}],"source":["# utils.util\n","\n","from __future__ import print_function\n","\n","import math\n","import torch\n","import torch.optim as optim\n","import numpy as np\n","!pip install ood_metrics\n","from ood_metrics import calc_metrics\n","from sklearn.metrics import roc_curve\n","\n","\n","\n","class TwoCropTransform:\n","    \"\"\"Create two crops of the same image\"\"\"\n","\n","    def __init__(self, transform):\n","        self.transform = transform\n","\n","    def __call__(self, x):\n","        return self.transform(x), self.transform(x)\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        _, pred = output.topk(maxk, 1, True, True)\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res\n","\n","\n","def adjust_learning_rate(args, optimizer, epoch):\n","    lr = args.learning_rate\n","    if args.cosine:\n","        eta_min = lr * (args.lr_decay_rate ** 3)\n","        lr = eta_min + (lr - eta_min) * (\n","                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n","    else:\n","        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n","        if steps > 0:\n","            lr = lr * (args.lr_decay_rate ** steps)\n","\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","\n","def warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n","    if args.warm and epoch <= args.warm_epochs:\n","        p = (batch_id + (epoch - 1) * total_batches) / \\\n","            (args.warm_epochs * total_batches)\n","        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n","\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = lr\n","\n","\n","def set_optimizer(opt, model):\n","    optimizer = optim.SGD(model.parameters(),\n","                          lr=opt.learning_rate,\n","                          momentum=opt.momentum,\n","                          weight_decay=opt.weight_decay)\n","    return optimizer\n","\n","\n","def calc_metrics_transformed(ind_score: np.ndarray, ood_score: np.ndarray) -> dict:\n","    labels = [1] * len(ind_score) + [0] * len(ood_score)\n","    scores = np.hstack([ind_score, ood_score])\n","\n","    metric_dict = calc_metrics(scores, labels)\n","    fpr, tpr, _ = roc_curve(labels, scores)\n","\n","    metric_dict_transformed = {\n","        \"AUROC\": 100 * metric_dict[\"auroc\"],\n","        #    \"TNR at TPR 95%\": 100 * (1 - metric_dict[\"fpr_at_95_tpr\"]),\n","        #   \"Detection Acc.\": 100 * 0.5 * (tpr + 1 - fpr).max(),\n","    }\n","    return metric_dict_transformed"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"556cdffb-8574-4189-baa4-483168bb765f","_uuid":"cfe2c9d9-0bc0-4c3b-8e15-d0861f09df55","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# conResNet\n","\n","\"\"\"ResNet in PyTorch.\n","ImageNet-Style ResNet\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","Adapted from: https://github.com/bearpaw/pytorch-classification\n","\"\"\"\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, is_last=False):\n","        super(BasicBlock, self).__init__()\n","        self.is_last = is_last\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        preact = out\n","        out = F.relu(out)\n","        if self.is_last:\n","            return out, preact\n","        else:\n","            return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1, is_last=False):\n","        super(Bottleneck, self).__init__()\n","        self.is_last = is_last\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        preact = out\n","        out = F.relu(out)\n","        if self.is_last:\n","            return out, preact\n","        else:\n","            return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, in_channel=3, zero_init_residual=False):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=3, stride=1, padding=1,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves\n","        # like an identity. This improves the model by 0.2~0.3% according to:\n","        # https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for i in range(num_blocks):\n","            stride = strides[i]\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, layer=100):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.avgpool(out)\n","        out = torch.flatten(out, 1)\n","        return out\n","\n","\n","def resnet18(**kwargs):\n","    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n","\n","\n","def resnet34(**kwargs):\n","    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n","\n","\n","def resnet50(**kwargs):\n","    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n","\n","\n","def resnet101(**kwargs):\n","    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n","\n","\n","model_dict = {\n","    'resnet18': [resnet18, 512],\n","    'resnet34': [resnet34, 512],\n","    'resnet50': [resnet50, 2048],\n","    'resnet101': [resnet101, 2048],\n","}\n","\n","\n","class LinearBatchNorm(nn.Module):\n","    \"\"\"Implements BatchNorm1d by BatchNorm2d, for SyncBN purpose\"\"\"\n","\n","    def __init__(self, dim, affine=True):\n","        super(LinearBatchNorm, self).__init__()\n","        self.dim = dim\n","        self.bn = nn.BatchNorm2d(dim, affine=affine)\n","\n","    def forward(self, x):\n","        x = x.view(-1, self.dim, 1, 1)\n","        x = self.bn(x)\n","        x = x.view(-1, self.dim)\n","        return x\n","\n","\n","class conResNet(nn.Module):\n","    \"\"\"backbone + projection head\"\"\"\n","\n","    def __init__(self, name='resnet50', head='mlp', feat_dim=128, n_heads=5):\n","        super(conResNet, self).__init__()\n","\n","        model_fun, dim_in = model_dict[name]\n","        self.total_var = 0\n","        self.encoder = model_fun()\n","        self.proj = []\n","        self.n_heads = n_heads\n","        if head == 'linear':\n","            self.head = nn.Linear(dim_in, feat_dim)\n","        elif head == 'mlp':\n","            self.proj = nn.ModuleList()\n","            for _ in range(n_heads):\n","                pro = nn.Sequential(\n","                    nn.Linear(dim_in, dim_in),\n","                    nn.ReLU(inplace=True),\n","                    nn.Linear(dim_in, feat_dim)\n","                )\n","                self.proj.append(pro)\n","\n","        else:\n","            raise NotImplementedError(\n","                'head not supported: {}'.format(head))\n","\n","    def forward(self, x1, x2):\n","        f1 = self.encoder(x1)\n","        f2 = self.encoder(x2)\n","        res1 = []\n","        res2 = []\n","        for i in range(self.n_heads):\n","            res1.append(F.normalize(self.proj[i](f1), dim=1))\n","            res2.append(F.normalize(self.proj[i](f2), dim=1))\n","        feat1 = torch.mean(torch.stack(res1), dim=0)\n","        feat2 = torch.mean(torch.stack(res2), dim=0)\n","        feat1_std = torch.sqrt(torch.var(torch.stack(res1), dim=0) + 0.0001)\n","        feat2_std = torch.sqrt(torch.var(torch.stack(res2), dim=0) + 0.0001)\n","        features = torch.cat([feat1.unsqueeze(1), feat2.unsqueeze(1)], dim=1)\n","        features_std = torch.cat([feat1_std.unsqueeze(1), feat2_std.unsqueeze(1)], dim=1)\n","\n","        return features, features_std\n","\n","\n","class LinearClassifier(nn.Module):\n","    \"\"\"Linear classifier\"\"\"\n","\n","    def __init__(self, name='resnet50', num_classes=10):\n","        super(LinearClassifier, self).__init__()\n","\n","        _, dim_in = model_dict[name]\n","        self.fc = nn.Linear(dim_in, num_classes)\n","\n","    def forward(self, features):\n","        return self.fc(features)\n","\n","\n","class MultiHeadSegResNet(nn.Module):\n","    def __init__(self, name='resnet50', num_classes=10, n_heads=5):\n","        super(MultiHeadSegResNet, self).__init__()\n","        model_fun, _ = model_dict[name]\n","        self.encoder = model_fun()\n","        self.n_heads = n_heads\n","        \n","        # Create multiple segmentation heads\n","        self.segmentation_heads = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(512, 256, kernel_size=3, padding=1),\n","                nn.ReLU(inplace=True),\n","                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n","                nn.Conv2d(256, 128, kernel_size=3, padding=1),\n","                nn.ReLU(inplace=True),\n","                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n","                nn.Conv2d(128, num_classes, kernel_size=1)\n","            ) for _ in range(n_heads)\n","        ])\n","    \n","    def forward(self, x):\n","        # Encode the input\n","        encoded_features = self.encoder(x)\n","        \n","        # Get segmentation output from each head\n","        seg_maps = [head(encoded_features) for head in self.segmentation_heads]\n","        \n","        # Stack outputs to compute mean and variance\n","        seg_maps_stack = torch.stack(seg_maps, dim=0)\n","        \n","        # Compute mean and variance across the heads for each pixel\n","        mean_seg_maps = torch.mean(seg_maps_stack, dim=0)\n","        variance_seg_maps = torch.var(seg_maps_stack, dim=0)\n","        \n","        return mean_seg_maps, variance_seg_maps, seg_maps"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"6b1345b8-9419-49bf-a933-164b5f67664d","_uuid":"7d3ef8e6-4ab2-4221-b1d6-900e836613f5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/sergio/.env/FEUP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# UALoss\n","\n","from __future__ import print_function\n","\n","import torch\n","import torch_xla.core.xla_model as xm\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class UALoss(nn.Module):\n","\n","    def __init__(self, temperature=0.07, contrast_mode='all',\n","                 base_temperature=0.07, lamda1=1, lamda2=0.1, batch_size=512):\n","        super(UALoss, self).__init__()\n","        self.temperature = temperature\n","        self.contrast_mode = contrast_mode\n","        self.base_temperature = base_temperature\n","        self.lamda1 = lamda1\n","        self.lamda2 = lamda2\n","        self.batch_size = batch_size\n","\n","    def forward(self, features, features_std, epochs):\n","        \"\"\"\n","\n","        Args:\n","            features: hidden vector of shape [bsz, n_views, ...].\n","            labels: ground truth of shape [bsz].\n","            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n","                has the same class as sample i. Can be asymmetric.\n","        Returns:\n","            A loss scalar.\n","        \"\"\"\n","        # print(features_std.shape)\n","        try:\n","            # Attempt to create a TPU device\n","            device = xm.xla_device()\n","            device_type = 'TPU'\n","        except RuntimeError as e:\n","            # Fallback to CUDA or CPU\n","            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","            device_type = 'GPU' if torch.cuda.is_available() else 'CPU'\n","\n","        print(f\"Using device: {device_type}, {device}\")\n","\n","        if len(features.shape) < 3:\n","            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n","                             'at least 3 dimensions are required')\n","        if len(features.shape) > 3:\n","            features = features.view(features.shape[0], features.shape[1], -1)\n","\n","        batch_size = features.shape[0]\n","\n","        mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n","\n","        contrast_count = features.shape[1]\n","        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n","        anchor_feature = contrast_feature\n","        anchor_count = contrast_count\n","\n","        # compute logits\n","        anchor_dot_contrast = torch.div(\n","            torch.matmul(anchor_feature, contrast_feature.T),\n","            self.temperature)\n","        # for numerical stability\n","        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n","        logits = anchor_dot_contrast - logits_max.detach()\n","\n","        # tile mask\n","        mask = mask.repeat(anchor_count, contrast_count)\n","        # mask-out self-contrast cases\n","        logits_mask = torch.scatter(\n","            torch.ones_like(mask),\n","            1,\n","            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n","            0\n","        )\n","        mask = mask * logits_mask\n","\n","        # compute log_prob\n","        exp_logits = torch.exp(logits) * logits_mask\n","        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n","\n","        # compute mean of log-likelihood over positive\n","        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n","        # loss\n","        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n","        # uncertainty loss\n","        std_loss1 = torch.sum(F.relu(self.lamda2 - features_std)) / (2 * self.batch_size)\n","        std_loss2 = torch.sum(features_std) / (2 * self.batch_size)\n","        # print(std_loss)\n","        # nt xnet loss\n","        loss = loss.view(anchor_count, batch_size).mean()\n","\n","        if self.lamda1 > 0:\n","            total_loss = std_loss1 * self.lamda1 + loss\n","        else:\n","            total_loss = loss\n","\n","        return total_loss, std_loss1, std_loss2"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"9c0bcd80-4c6b-4c38-a6ef-9ff031f02d71","_uuid":"158c2e89-f2ed-42bd-99a4-8a1d62da8575","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# pretrain.py\n","\n","import sys\n","import time\n","import torch\n","# from utils.util import AverageMeter\n","# from utils.util import warmup_learning_rate\n","# from models.resnet_big import conResNet\n","# from utils.losses import UALoss\n","import torch.backends.cudnn as cudnn\n","from torch import nn\n","import torch_xla.core.xla_model as xm\n","import torch_xla.distributed.parallel_loader as pl\n","import torch_xla.distributed.xla_multiprocessing as xmp\n","from torch_xla.core.xla_model import optimizer_step\n","\n","\n","def train(train_loader, model, criterion, optimizer, epoch, opt):\n","    \"\"\"one epoch training\"\"\"\n","    device = xm.xla_device()\n","    model.train()\n","    \n","    # Metrics initialization\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    stdlosses = AverageMeter()\n","    stdlosses2 = AverageMeter()\n","\n","    # Convert DataLoader for TPU usage\n","    para_loader = pl.ParallelLoader(train_loader, [device])\n","    loader = para_loader.per_device_loader(device)\n","\n","    end = time.time()\n","    \n","    for idx, ((image1, image2), labels) in enumerate(loader):\n","        data_time.update(time.time() - end)\n","\n","        image1 = image1.to(device)\n","        image2 = image2.to(device)\n","        labels = labels.to(device)\n","        bsz = labels.shape[0]\n","\n","        # Warm-up and learning rate adjustment\n","        # Note: You'll need to adjust or implement warmup_learning_rate for TPUs if necessary\n","\n","        # Forward pass, loss computation, and backward pass\n","        features, features_std = model(image1, image2)\n","        loss, std_loss, std_loss2 = criterion(features, features_std, epoch)\n","        \n","        losses.update(loss.item(), bsz)\n","        stdlosses.update(std_loss.item(), bsz)\n","        stdlosses2.update(std_loss2.item(), bsz)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        xm.optimizer_step(optimizer)\n","        xm.mark_step()  # Marking the step is crucial for TPU computation\n","\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if (idx + 1) % opt.print_freq == 0:\n","            print(f'Train: [{epoch}][{idx + 1}/{len(loader)}]\\t'\n","                  f'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  f'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  f'Loss {losses.val:.3f} ({losses.avg:.3f})')\n","\n","    return losses.avg, stdlosses.avg, stdlosses2.avg\n","\n","\n","\n","def set_model(model_name, temperature, syncBN=False, lamda1=1, lamda2=0.1, batch_size=512, nh=5):\n","    # Define the device as TPU or fall back to CUDA/CPU\n","    device = xm.xla_device()\n","    \n","    model = conResNet(name=model_name, n_heads=nh)\n","    criterion = UALoss(temperature=temperature, lamda1=lamda1, lamda2=lamda2, batch_size=batch_size)\n","    \n","    model = model.to(device)\n","    criterion = criterion.to(device)\n","    \n","    # Synchronized batch normalization using PyTorch XLA's implementation\n","    if syncBN:\n","        model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n","\n","    return model, criterion"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"54356e52-a873-4604-89e5-3cd7231ebd50","_uuid":"bc0a0a80-6970-40e5-8280-26eff6768828","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# dataloader\n","\n","from torch.utils.data import DataLoader, random_split\n","import torchvision.transforms as transforms\n","from torchvision import datasets\n","import torch\n","# from utils.util import TwoCropTransform\n","\n","\n","def data_loader(dataset=\"cifar10\", batch_size=512, semi=False, semi_percent=10, num_cores=12):\n","    if dataset == 'cifar10':\n","        mean = (0.4914, 0.4822, 0.4465)\n","        std = (0.2023, 0.1994, 0.2010)\n","    elif dataset == 'cifar100':\n","        mean = (0.5071, 0.4867, 0.4408)\n","        std = (0.2675, 0.2565, 0.2761)\n","    elif dataset == 'cifar10h':\n","        mean = (0.4914, 0.4822, 0.4465)\n","        std = (0.2023, 0.1994, 0.2010)\n","    elif dataset == \"svhn\":\n","        mean = (0.4376821, 0.4437697, 0.47280442)\n","        std = (0.19803012, 0.20101562, 0.19703614)\n","\n","    normalize = transforms.Normalize(mean=mean, std=std)\n","    train_transform = transforms.Compose([\n","        transforms.RandomResizedCrop(size=32, scale=(0.2, 1.)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","    val_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","    sampler = None\n","    # datasets\n","    if dataset == \"cifar10\":\n","        train_dataset = datasets.CIFAR10(root='../../DATA2/', train=True, download=True, transform=train_transform)\n","        test_dataset = datasets.CIFAR10(root='../../DATA2/', train=False, download=True, transform=val_transform)\n","\n","    elif dataset == \"cifar100\":\n","        train_dataset = datasets.CIFAR100(root='../../DATA2/', train=True, download=True, transform=train_transform)\n","        test_dataset = datasets.CIFAR100(root='../../DATA2/', train=False, download=True, transform=val_transform)\n","    elif dataset == \"svhn\":\n","        train_dataset = datasets.SVHN(\n","            root='.../../DATA2/', split=\"train\", download=True, transform=train_transform\n","        )\n","        test_dataset = datasets.SVHN(\n","            root='../../DATA2/', split=\"test\", download=True, transform=val_transform\n","        )\n","    if semi:\n","        per = semi_percent / 100\n","        x = int(per * len(train_dataset))\n","        y = int(len(train_dataset) - x)\n","        train, _ = random_split(train_dataset, [x, y])\n","    else:\n","        train = train_dataset\n","\n","    train, val = random_split(train, [int(0.8 * len(train)),\n","                                      len(train) - int(0.8 * len(train))], generator=torch.Generator().manual_seed(42))\n","\n","    train_loader = DataLoader(train,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=num_cores,\n","                              drop_last=False\n","                              )\n","    val_loader = DataLoader(val,\n","                            batch_size=batch_size,\n","                            shuffle=False,\n","                            num_workers=num_cores,\n","                            drop_last=False)\n","\n","    test_loader = DataLoader(test_dataset,\n","                             batch_size=batch_size,\n","                             num_workers=num_cores,\n","                             drop_last=False)\n","\n","    targets = torch.cat([y for x, y in test_loader], dim=0).numpy()\n","    return train_loader, val_loader, test_loader, targets\n","\n","\n","def set_loader_simclr(dataset, batch_size, num_workers, data_dir='../../DATA2/', size=32):\n","    # construct data loader\n","    if dataset == 'cifar10':\n","        mean = (0.4914, 0.4822, 0.4465)\n","        std = (0.2023, 0.1994, 0.2010)\n","    elif dataset == 'cifar100':\n","        mean = (0.5071, 0.4867, 0.4408)\n","        std = (0.2675, 0.2565, 0.2761)\n","    elif dataset == \"svhn\":\n","        mean = (0.4376821, 0.4437697, 0.47280442)\n","        std = (0.19803012, 0.20101562, 0.19703614)\n","    else:\n","        raise ValueError('dataset not supported: {}'.format(dataset))\n","    normalize = transforms.Normalize(mean=mean, std=std)\n","\n","    train_transform = transforms.Compose([\n","        transforms.RandomResizedCrop(size=size, scale=(0.2, 1.)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomApply([\n","            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n","        ], p=0.8),\n","        transforms.RandomGrayscale(p=0.2),\n","        transforms.ToTensor(),\n","        normalize,\n","    ])\n","\n","    if dataset == 'cifar10':\n","        train_dataset = datasets.CIFAR10(root=data_dir,\n","                                         transform=TwoCropTransform(train_transform),\n","                                         download=True)\n","    elif dataset == 'cifar100':\n","        train_dataset = datasets.CIFAR100(root=data_dir,\n","                                          transform=TwoCropTransform(train_transform),\n","                                          download=True)\n","    elif dataset == 'svhn':\n","        train_dataset = datasets.SVHN(\n","            root=data_dir, split=\"train\", download=True, transform=TwoCropTransform(train_transform)\n","        )\n","\n","    else:\n","        raise ValueError(dataset)\n","\n","    train_sampler = None\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, shuffle=(train_sampler is None),\n","        num_workers=num_workers, pin_memory=False, sampler=train_sampler)\n","\n","    return train_loader"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"4a4d0cb0-a913-4192-945c-cb6c2f8f6fc6","_uuid":"c20ae267-4b15-497f-aa83-4d69b61e510d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorboard_logger in /home/sergio/.env/FEUP/lib/python3.10/site-packages (0.1.0)\n","Requirement already satisfied: six in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from tensorboard_logger) (1.16.0)\n","Requirement already satisfied: protobuf in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from tensorboard_logger) (3.20.3)\n","Requirement already satisfied: pillow>=4.1.1 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from tensorboard_logger) (10.2.0)\n","Requirement already satisfied: scipy>=0.19.1 in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from tensorboard_logger) (1.12.0)\n","Requirement already satisfied: numpy in /home/sergio/.env/FEUP/lib/python3.10/site-packages (from tensorboard_logger) (1.26.4)\n","THIS: .\n","Files already downloaded and verified\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:PJRT is now the default runtime. For more information, see https://github.com/pytorch/xla/blob/master/docs/pjrt.md\n","WARNING:root:Defaulting to PJRT_DEVICE=CPU\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1710869146.725114   12251 cpu_client.cc:370] TfrtCpuClient created.\n"]},{"name":"stdout","output_type":"stream","text":["Using device: TPU, xla:0\n"]}],"source":["from __future__ import print_function\n","\n","import sys\n","import os\n","import argparse\n","import time\n","import math\n","import pandas as pd\n","!pip install tensorboard_logger\n","import tensorboard_logger as tb_logger\n","import torch\n","# from Train.pretrain import train, set_model\n","# from Dataloader.dataloader import set_loader_simclr\n","\n","# from utils.util import adjust_learning_rate\n","# from utils.util import set_optimizer\n","\n","# try:\n","#    import apex\n","#    from apex import amp, optimizers\n","# except ImportError:\n","#    pass\n","\n","\n","def parse_option():\n","    parser = argparse.ArgumentParser('argument for training')\n","\n","    parser.add_argument('--print_freq', type=int, default=10,\n","                        help='print frequency')\n","    parser.add_argument('--batch_size', type=int, default=64,\n","                        help='batch_size')\n","    parser.add_argument('--num_workers', type=int, default=12,\n","                        help='num of workers to use')\n","    parser.add_argument('--epochs', type=int, default=800,\n","                        help='number of training epochs')\n","    parser.add_argument('--ensemble', type=int, default=1,\n","                        help='number of ensemble')\n","    # optimization\n","    parser.add_argument('--learning_rate', type=float, default=0.01,\n","                        help='learning rate')\n","    parser.add_argument('--lr_decay_epochs', type=str, default='700,800,900',\n","                        help='where to decay lr, can be a list')\n","    parser.add_argument('--lr_decay_rate', type=float, default=0.1,\n","                        help='decay rate for learning rate')\n","    parser.add_argument('--weight_decay', type=float, default=1e-4,\n","                        help='weight decay')\n","    parser.add_argument('--momentum', type=float, default=0.9,\n","                        help='momentum')\n","\n","    # model dataset\n","    parser.add_argument('--model', type=str, default='resnet50')\n","    parser.add_argument('--dataset', type=str, default='cifar10',\n","                        choices=['cifar10', 'cifar100'], help='dataset')\n","    parser.add_argument('--data_folder', type=str, default=None, help='path to custom dataset')\n","    parser.add_argument('--size', type=int, default=32, help='parameter for RandomResizedCrop')\n","\n","    # hyperparameters\n","    parser.add_argument('--temp', type=float, default=0.07,\n","                        help='temperature for loss function')\n","    parser.add_argument('--nh', type=int, default=10,\n","                        help='number of heads')\n","    parser.add_argument('--lamda1', type=float, default=1,\n","                        help='uncertainty_penalty_weight')\n","    parser.add_argument('--lamda2', type=float, default=0.8,\n","                        help='uncertainty_threshold')\n","\n","    # other setting\n","    parser.add_argument('--cosine', action='store_true',\n","                        help='using cosine annealing')\n","    parser.add_argument('--warm', action='store_true',\n","                        help='warm-up for large batch training')\n","    parser.add_argument('--saved_model', type=str, default=\".\",\n","                        help='path to save classifier')\n","    parser.add_argument('--log', type=str, default='.',\n","                        help='path to save tensorboard logs')\n","    parser.add_argument('--syncBN', action='store_true', \n","                        help='enable synchronized batch normalization')\n","    \n","\n","    opt = parser.parse_args()\n","\n","    # set the path according to the environment\n","    if opt.data_folder is None:\n","        opt.data_folder = './DATA'\n","    opt.tb_path = os.path.join(opt.log, '{}'.format(opt.dataset))\n","    print(f\"THIS: {opt.saved_model}\")\n","    opt.save_folder = os.path.join(opt.saved_model, '{}_experiments'.format(opt.dataset))\n","    if not os.path.isdir(opt.save_folder):\n","        os.makedirs(opt.save_folder)\n","    if opt.batch_size > 256:\n","        opt.warm = True\n","    if opt.warm:\n","        opt.warmup_from = 0.01\n","        opt.warm_epochs = 10\n","        if opt.cosine:\n","            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n","            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n","                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n","        else:\n","            opt.warmup_to = opt.learning_rate\n","    return opt\n","\n","\n","def main():\n","    sys.argv = ['main_pretrain.py', '--cosine', '--dataset', 'cifar10', '--lamda1', '1', '--lamda2', '0.08', '--epochs', '800']\n","    opt = parse_option()\n","\n","    torch.cuda.empty_cache()\n","    # build data loader\n","    train_loader = set_loader_simclr(dataset=opt.dataset, batch_size=opt.batch_size, num_workers=opt.num_workers,\n","                                     size=opt.size)\n","\n","    for i in range(opt.ensemble):\n","        torch.manual_seed(i)\n","        torch.cuda.manual_seed(i)\n","        model, criterion = set_model(model_name=opt.model, temperature=opt.temp, syncBN=opt.syncBN, lamda1=opt.lamda1,\n","                                     lamda2=opt.lamda2,\n","                                     batch_size=opt.batch_size, nh=opt.nh)\n","\n","        # build optimizer\n","        optimizer = set_optimizer(opt, model)\n","\n","        # tensorboard\n","        logger = tb_logger.Logger(logdir=opt.tb_path, flush_secs=2)\n","\n","        time1 = time.time()\n","        l1 = []\n","        l2 = []\n","        l3 = []\n","        # training routine\n","        for epoch in range(1, opt.epochs + 1):\n","            adjust_learning_rate(opt, optimizer, epoch)\n","            # train for one epoch\n","            time3 = time.time()\n","            loss, std_loss, std_loss2 = train(train_loader, model, criterion, optimizer, epoch, opt)\n","            time4 = time.time()\n","            print('ensemble {}, epoch {}, total time {:.2f}'.format(i, epoch, time4 - time3))\n","            l1.append(loss)\n","            l2.append(std_loss)\n","            l3.append(std_loss2)\n","            # tensorboard logger\n","            logger.log_value('loss', loss, epoch)\n","            logger.log_value('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n","            # logger.log_value('std', std_loss, epoch)\n","            checkpoint_file = os.path.join(\n","            \".\",\n","            'simclr_{}_{}_recent_{}heads_lamda1{}_lamda2{}.pth'.format(opt.dataset, i, opt.nh,\n","                                                                          opt.lamda1,\n","                                                                          opt.lamda2))\n","            torch.save(model.state_dict(), checkpoint_file)\n","\n","        time2 = time.time()\n","        print('ensemble {}, total time {:.2f}'.format(i, time2 - time1))\n","        loss_res = pd.DataFrame({\"total_loss\": l1, \"stdloss1\": l2, \"stdloss2\": l3})\n","        os.makedirs(\"./csv_loss\", exist_ok=True)\n","        loss_res.to_csv(\n","            \"./csv_loss/{}_c_{}heads_lamda1{}_lamda2{}.csv\".format(opt.dataset, opt.nh, opt.lamda1, opt.lamda2))\n","        save_file = os.path.join(\n","            opt.save_folder,\n","            'simclr_{}_{}_epoch{}_{}heads_lamda1{}_lamda2{}.pth'.format(opt.dataset, i, opt.epochs, opt.nh,\n","                                                                          opt.lamda1,\n","                                                                          opt.lamda2))\n","        torch.save(model.state_dict(), save_file)\n","\n","\n","if __name__ == '__main__':\n","    main()"]}],"metadata":{"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":30666,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
